---
title: "Assignment 2"
author: "PLSC 21510/31510"
date: "Fall 2022"
output: pdf_document
---

### Instructions

- __Assigned__: Oct 6
- __Due__: Oct 13

Answer the questions below. Knit this `.Rmd` document as a pdf and submit the pdf file in Canvas. Please avoid printing long outputs (like entire dataframes). 

```{r message = FALSE}
library(tidyverse)
library(rvest)
library(stringr)
library(purrr)
library(lubridate)
library(rtweet)
```

## Part 1: Webscraping

In this week's lecture, we introduced some tools to collect pieces of data from individual presidential documents. For this assignment, we will be looking at __all__ documents in the database that contain the string "space exploration." Our goals in this problem set are:

1. To scrape all documents returned from [this search query](https://www.presidency.ucsb.edu/advanced-search?field-keywords=%22space+exploration%22&field-keywords2=&field-keywords3=&from%5Bdate%5D=&to%5Bdate%5D=&person2=&items_per_page=100)

2. To organize this data into a dataframe and ultimately output a CSV file.

Below, I've given you the code for a function that passes the URL of an individual document, scrapes the information from that document, and returns this information in a list.

You must complete the rest of the task yourself. Specifically, you should:

1. Write code that scrapes all documents, organizes the information in a dataframe, and writes a csv file.

2. The end goal should be a dataset identical to the one I've provided for you in `data/space.csv`.

3. Split the code up into discrete steps, each with their own corresponding Rmarkdown chunk. Use subheaders as necessary.

4. Document (i.e. describe) each step in clear but concise Rmarkdown prose.

5. The final chunk should:
  * print the structure (`str`) of the final data frame.
  * write the dataframe to a csv file. 

Onward!

```{r}
scrape_docs <- function(URL){
  doc <- read_html(URL)

  speaker <- html_nodes(doc, ".diet-title a") %>% 
    html_text()
  
  date <- html_nodes(doc, ".date-display-single") %>%
    html_text() %>%
    mdy()
  
  title <- html_nodes(doc, "h1") %>%
    html_text()
  
  text <- html_nodes(doc, "div.field-docs-content") %>%
    html_text()
  
  all_info <- list(speaker = speaker, date = date, title = title, text = text)
  
  # print statement
  print(str_c("Scraping... ", title))
  
  return(all_info)
}
```


## Part 2: RTweet

Work through the tutorial `2_Collecting/4_RTweet-Demo.Rmd`, which can be found in the main course materials. Below, enter your answers to the challenges.

#### Challenge 1: Hashtag Challenge.

Using the documentation for `search_tweets` as a guide, try pulling the 2,000 most recent tweets that include `#DukeEllington` OR `"Duke Ellington"` -- be sure to exclude retweets from the query.

1. Why did your query not return 2,000 results?

2. Identify the user that has used either the hashtag or the string in the greatest number of tweets -- where is this user from?

```{r, message=FALSE}
# YOUR CODE HERE
```

#### Challenge 2.

Of the 5 twitter-using IR profs, which one has the highest follower to friend ratio? 

The IR profs handles are: @carsonaust, @profpaulpoast, @pstanpolitics, @rochelleterman, @bobbygulotty)

```{r}
# YOUR CODE HERE
```


#### Challenge 3 (extra credit). 

Pick your favorite musical artist and collect the 1,000 most recent tweets they are mentioned in (either by their handle or plain text). What is the most frequently used hashtag in these tweets other than #artistname? 

**Hint**: Hashtags can be found in the nexted column `entities`

```{r}
# YOUR CODE HERE
```

